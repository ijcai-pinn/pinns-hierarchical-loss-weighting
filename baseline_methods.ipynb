{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f4637-ed4b-402f-ade4-15942fcf12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0e354-992f-4314-9fb7-887badd30b9e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beade53-1b63-4e13-b4ab-aa7219bfba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ...\n",
    "\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f7fcf-7dc6-4f1e-921a-e9a8b4f47d45",
   "metadata": {},
   "source": [
    "# SVM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4734980-fbfb-4897-8f8b-7327de605c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svr\", SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svr__kernel\": [\"rbf\"],\n",
    "    \"svr__C\": [0.1, 1, 10, 100],\n",
    "    \"svr__epsilon\": [0.01, 0.1, 0.5],\n",
    "    \"svr__gamma\": [\"scale\", 0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, pred))\n",
    "print(\"Test R2 :\", r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706c2eb-2eb7-4840-95b6-2604ddea5802",
   "metadata": {},
   "source": [
    "# XGBost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30908fad-12fc-4584-ab8b-eacd03ac32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    # optional speed-ups:\n",
    "    # tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [500, 1000, 2000],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 4, 6, 8],\n",
    "    \"min_child_weight\": [1, 3, 5, 10],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_lambda\": [0.0, 1.0, 5.0, 10.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "search.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, pred))\n",
    "print(\"Test R2 :\", r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcac6b0-3f4c-4ae1-a78d-39070dc43e8d",
   "metadata": {},
   "source": [
    "# Kerenl Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63591adf-4831-42eb-a49f-f3e764e63af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"krr\", KernelRidge(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"krr__alpha\": [1e-3, 1e-2, 1e-1, 1, 10, 100],     # regularization strength\n",
    "    \"krr__gamma\": [1e-3, 1e-2, 1e-1, 1, 10],          # RBF width (higher = wiggly)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, pred))\n",
    "print(\"Test R2 :\", r2_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa371e6-e3c2-4ce1-ad99-f90001239082",
   "metadata": {},
   "source": [
    "# Graph Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96df6d-6966-462b-9f2c-eb480eddc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spla\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def knn_rbf_adjacency(X, n_neighbors=15, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Build sparse symmetric adjacency W using kNN and RBF weights:\n",
    "      w_ij = exp(-||xi-xj||^2 / (2*sigma^2))\n",
    "    \"\"\"\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors + 1, metric=\"euclidean\").fit(X)\n",
    "    dists, idx = nn.kneighbors(X)\n",
    "\n",
    "    # drop self-neighbor at column 0\n",
    "    dists = dists[:, 1:]\n",
    "    idx = idx[:, 1:]\n",
    "\n",
    "    n = X.shape[0]\n",
    "    rows = np.repeat(np.arange(n), n_neighbors)\n",
    "    cols = idx.reshape(-1)\n",
    "\n",
    "    weights = np.exp(-(dists.reshape(-1) ** 2) / (2.0 * sigma**2))\n",
    "\n",
    "    W = sp.csr_matrix((weights, (rows, cols)), shape=(n, n))\n",
    "    W = 0.5 * (W + W.T)  # symmetrize\n",
    "    return W\n",
    "\n",
    "def graph_laplacian(W: sp.spmatrix) -> sp.spmatrix:\n",
    "    d = np.asarray(W.sum(axis=1)).ravel()\n",
    "    return sp.diags(d) - W\n",
    "\n",
    "def laplacian_regression(L: sp.spmatrix, y: np.ndarray, labeled_idx, lam=1.0, ridge=1e-8):\n",
    "    n = L.shape[0]\n",
    "    labeled_idx = np.array(labeled_idx, dtype=int)\n",
    "\n",
    "    m = np.zeros(n)\n",
    "    m[labeled_idx] = 1.0\n",
    "    M = sp.diags(m)\n",
    "\n",
    "    A = M + lam * L + ridge * sp.eye(n, format=\"csr\")\n",
    "    b = M @ y\n",
    "    return spla.spsolve(A.tocsr(), b)\n",
    "\n",
    "# ---- Demo data (replace with your real X,y where y is known only for some nodes) ----\n",
    "rng = np.random.RandomState(0)\n",
    "n, p = 800, 10\n",
    "X = rng.randn(n, p)\n",
    "\n",
    "# Underlying smooth-ish signal + noise\n",
    "y_full = X @ rng.uniform(-2, 2, size=p) + 0.5 * rng.randn(n)\n",
    "\n",
    "# Suppose only some nodes are labeled\n",
    "labeled_idx = rng.choice(n, size=120, replace=False)\n",
    "\n",
    "# 1) scale features (important for kNN/RBF)\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "# 2) build graph\n",
    "W = knn_rbf_adjacency(Xs, n_neighbors=20, sigma=1.0)\n",
    "L = graph_laplacian(W)\n",
    "\n",
    "# 3) tune lambda using CV on labeled nodes (hide some labeled each fold)\n",
    "lambdas = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_lam, best_cv = None, float(\"inf\")\n",
    "\n",
    "for lam in lambdas:\n",
    "    fold_mses = []\n",
    "    for train_idx, val_idx in kf.split(labeled_idx):\n",
    "        train_labeled = labeled_idx[train_idx]\n",
    "        val_labeled   = labeled_idx[val_idx]\n",
    "\n",
    "        f_hat = laplacian_regression(L, y_full, train_labeled, lam=lam)\n",
    "        fold_mses.append(mean_squared_error(y_full[val_labeled], f_hat[val_labeled]))\n",
    "\n",
    "    cv_mse = float(np.mean(fold_mses))\n",
    "    if cv_mse < best_cv:\n",
    "        best_cv, best_lam = cv_mse, lam\n",
    "\n",
    "# 4) fit with best lambda using all labeled nodes\n",
    "f_final = laplacian_regression(L, y_full, labeled_idx, lam=best_lam)\n",
    "\n",
    "print(\"Best lambda:\", best_lam, \"CV MSE:\", best_cv)\n",
    "print(\"Predictions for all nodes available in f_final (length =\", len(f_final), \")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
